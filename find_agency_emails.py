#!/usr/bin/env python3
"""
–ü–æ–∏—Å–∫ email'–æ–≤ –¥–ª—è –∞–≥–µ–Ω—Ç—Å—Ç–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –ú–æ—Å–∫–≤—ã
1. –ü–æ–∏—Å–∫ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∞–π—Ç–æ–≤ —á–µ—Ä–µ–∑ Google
2. –ü–∞—Ä—Å–∏–Ω–≥ email'–æ–≤ —Å —Å–∞–π—Ç–æ–≤
3. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
"""

import json
import time
import re
import requests
from playwright import sync_api
import random

def load_agencies():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞ –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –±–µ–∑ email'–æ–≤"""
    with open('./georeview-parsing/leads/–º–æ—Å–∫–≤–∞_–∞–≥–µ–Ω—Ç—Å—Ç–≤–∞_yell_final_2026-02-25.json', 'r', encoding='utf-8') as f:
        agencies = json.load(f)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –±–µ–∑ –Ω–∞—Å—Ç–æ—è—â–∏—Ö email'–æ–≤
    no_email = [a for a in agencies if not a.get('email') or a.get('email') == 'biz@yell.ru']
    with_phone = [a for a in no_email if a.get('phone')]
    
    print(f"üìä –í—Å–µ–≥–æ –∞–≥–µ–Ω—Ç—Å—Ç–≤: {len(agencies)}")
    print(f"‚ùå –ë–µ–∑ –Ω–∞—Å—Ç–æ—è—â–∏—Ö email: {len(no_email)}")
    print(f"üìû –° —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(with_phone)}")
    
    return with_phone

def extract_emails_from_text(text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç email'—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    emails = re.findall(email_pattern, text, re.IGNORECASE)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ email'—ã
    filtered = []
    exclude_domains = ['yell.ru', 'vk.com', 'gmail.com', 'mail.ru', 'yandex.ru']
    
    for email in emails:
        domain = email.split('@')[1].lower()
        if not any(exc in domain for exc in exclude_domains):
            filtered.append(email)
    
    return list(set(filtered))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã

def find_website_via_google(agency_name, browser):
    """–ò—â–µ—Ç –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞ —á–µ—Ä–µ–∑ Google"""
    try:
        page = browser.new_page()
        
        # –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        query = f'"{agency_name}" –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å –ú–æ—Å–∫–≤–∞ —Å–∞–π—Ç -vk.com -yell.ru'
        search_url = f"https://www.google.com/search?q={requests.utils.quote(query)}"
        
        print(f"   üîç –ü–æ–∏—Å–∫ —Å–∞–π—Ç–∞ –≤ Google...")
        page.goto(search_url, timeout=15000)
        time.sleep(random.uniform(2, 4))
        
        # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞
        links = page.locator('a[href^="http"]').all()
        
        for link in links[:10]:  # –ü–µ—Ä–≤—ã–µ 10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            try:
                href = link.get_attribute('href')
                if href and not any(domain in href for domain in ['google.com', 'yell.ru', 'vk.com', 'instagram.com', 'facebook.com']):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ —Ä–µ–∫–ª–∞–º–∞
                    if '/url?' not in href and href.startswith('http'):
                        page.close()
                        return href
            except:
                continue
        
        page.close()
        return None
        
    except Exception as e:
        print(f"     ‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Google: {e}")
        return None

def parse_email_from_website(website_url, browser):
    """–ü–∞—Ä—Å–∏—Ç email —Å —Å–∞–π—Ç–∞"""
    try:
        page = browser.new_page()
        
        print(f"   üåê –ü–∞—Ä—Å–∏–Ω–≥ {website_url}")
        page.goto(website_url, timeout=15000)
        time.sleep(2)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        page_text = page.text_content('body')
        
        # –ò—â–µ–º email'—ã
        emails = extract_emails_from_text(page_text)
        
        page.close()
        return emails
        
    except Exception as e:
        print(f"     ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {website_url}: {e}")
        return []

def process_agency(agency, browser):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ –∞–≥–µ–Ω—Ç—Å—Ç–≤–æ"""
    name = agency.get('name', '')
    phone = agency.get('phone', '')
    existing_website = agency.get('website', '')
    
    print(f"\nüè¢ {name}")
    print(f"   üìû {phone}")
    
    found_emails = []
    found_website = None
    
    # 1. –ï—Å–ª–∏ –µ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Å–∞–π—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ–≥–æ
    if existing_website and existing_website not in ['', 'https://vk.com/yellru']:
        if 'vk.com' not in existing_website:
            emails = parse_email_from_website(existing_website, browser)
            if emails:
                found_emails.extend(emails)
                found_website = existing_website
    
    # 2. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ email, –∏—â–µ–º –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç
    if not found_emails:
        website = find_website_via_google(name, browser)
        if website:
            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω —Å–∞–π—Ç: {website}")
            emails = parse_email_from_website(website, browser)
            if emails:
                found_emails.extend(emails)
                found_website = website
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞
    if found_emails:
        agency['email'] = found_emails[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π
        agency['all_emails'] = found_emails
        print(f"   üìß Email –Ω–∞–π–¥–µ–Ω: {found_emails[0]}")
    else:
        print(f"   ‚ùå Email –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    if found_website:
        agency['real_website'] = found_website
    
    return agency

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üìß –ü–æ–∏—Å–∫ email'–æ–≤ –¥–ª—è –∞–≥–µ–Ω—Ç—Å—Ç–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –ú–æ—Å–∫–≤—ã")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞
    agencies = load_agencies()
    
    if not agencies:
        print("‚ùå –ù–µ—Ç –∞–≥–µ–Ω—Ç—Å—Ç–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞
    test_limit = 10
    agencies_to_process = agencies[:test_limit]
    
    print(f"\nüéØ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ {len(agencies_to_process)} –∞–≥–µ–Ω—Ç—Å—Ç–≤ –¥–ª—è —Ç–µ—Å—Ç–∞")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
    with sync_api.sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        
        updated_agencies = []
        
        for i, agency in enumerate(agencies_to_process, 1):
            print(f"\n[{i}/{len(agencies_to_process)}]", end="")
            
            updated = process_agency(agency, browser)
            updated_agencies.append(updated)
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
            if i < len(agencies_to_process):
                wait_time = random.uniform(3, 6)
                print(f"   ‚è±Ô∏è –ü–∞—É–∑–∞ {wait_time:.1f} —Å–µ–∫...")
                time.sleep(wait_time)
        
        browser.close()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    output_file = './moscow_agencies_with_emails.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(updated_agencies, f, ensure_ascii=False, indent=2)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    found_emails = [a for a in updated_agencies if a.get('email') and a.get('email') != 'biz@yell.ru']
    
    print("\n" + "=" * 60)
    print("üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(updated_agencies)} –∞–≥–µ–Ω—Ç—Å—Ç–≤")
    print(f"üìß Email'–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {len(found_emails)} ({len(found_emails)/len(updated_agencies)*100:.0f}%)")
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ email'—ã
    if found_emails:
        print("\n‚úÖ –ù–∞–π–¥–µ–Ω–Ω—ã–µ email'—ã:")
        for agency in found_emails:
            print(f"   ‚Ä¢ {agency['name']}: {agency['email']}")

if __name__ == "__main__":
    main()